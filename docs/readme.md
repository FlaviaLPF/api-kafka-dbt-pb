# ‚úàÔ∏è Real-Time Flight Analytics: Engenharia de Dados com dbt & Star Schema


## üìå Sum√°rio
- [Sobre o Projeto](#-sobre-o-projeto)
- [Arquitetura do Sistema](#arquitetura-do-projeto-sistema)
- [Arquitetura Medallion](#arquitetura-medallion)
- [Modelo de dados](#modelagem-de-dados)
- [O DW](#-camada-gold-o-data-warehouse-dw)
- [Modelagem Dimensional - Star Schema](#-modelo-dimensional-star-schema)
- [Processos de Neg√≥cio](#-processos-de-neg√≥cio)
- [Hierarquia](#-hierarquias)
- [Fluxo de Dados (ETL)](#-fluxo-de-dados)
- [Insights de Neg√≥cio](./docs/visualizacao_dados.md#dashboards-e-insights)
- [Conclus√£o e Pr√≥ximos Passos](#-conclus√£o-e-pr√≥ximos-passos)

>**NOTA:**
>Para ver as evid√™ncias do pipeline em execu√ß√£o e os Dashboards finais, 
>acesse: Detalhamento Visual e Artefatos  ![Visualiza√ß√£o de Dados](./visualizacao_dados.md)

## üéØ Sobre o Projeto
Este projeto consiste em um pipeline de dados ponta a ponta para monitoramento e 
an√°lise do tr√°fego a√©reo na regi√£o de S√£o Paulo, utilizando dados reais da API OpenSky Network. 
O objetivo principal foi transformar dados brutos de telemetria em um Data Warehouse estruturado, permitindo an√°lises complexas sobre comportamento de v√¥o e ocupa√ß√£o do espa√ßo a√©reo.

### üõ†Ô∏è Caracter√≠sticas Principais

Lista das ferramentas:

  * Ingest√£o: Python + OpenSky API (fonte) (√© feita de 5 em 5 minutos)
  * Mensageria: Apache Kafka (para o streaming dos dados).
  * HDFS: faz o papel de Data Lake distribu√≠do, armazena arquivo parquet com dados recebidos pelo kafka e arquivos que controla o stage (voos que precisam ser processados), arquivo json com o schema de dados e arquivos tempor√°rios.
  * Spark cluster : deploy-mode client (master + workers) integrado ao Airflow.
  * Data Warehouse: SQL Server.
  * Transforma√ß√£o: dbt core (Data Build Tool) com modelos incrementais e Joins geogr√°ficos.
  * BI: Power BI (An√°lise de performance e hor√°rios de pico).
  * Airflow:  orchestrador de todo pipeline.
  * Docker: Todo o projeto foi containerizado utilizando Docker.  

Para garantir a escalabilidade e a qualidade das an√°lises, implementei uma arquitetura de medalh√£o (Bronze, Silver e Gold) utilizando o dbt (data build tool):

  * Modelagem Dimensional: Estrutura√ß√£o Star Schema otimizado para BI,
  separando m√©tricas volum√©tricas (Fatos) de contextos descritivos (Dimens√µes).
  * Hierarquias de Dados: Implementa√ß√£o de drill-down temporal (Ano > M√™s > Hora) e  geogr√°fico (Regi√£o > Estado > Aeroporto) para an√°lises granulares.
  * Geofencing: L√≥gica SQL para identifica√ß√£o autom√°tica de presen√ßa em aeroportos (GRU/CGH) baseada em coordenadas geogr√°ficas.
  * Qualidade de Dados: Aplica√ß√£o de testes automatizados de integridade, garantindo chaves √∫nicas, campos n√£o nulos e intervalos de valores aceit√°veis (ex: velocidade e altitude) e 
  cria√ß√£o de logs do contagem de registros entrada vs sa√≠da.
  * Idempot√™ncia: dag preparada para rodar novamente em caso de erros, sem a duplica√ß√£o 
  de dados no DW (utiliza√ß√£o de dynamic overwrite e parti√ß√µes por data).
  * Schema Enforcement: o schema de dados √© gravado em um JSON (SCHEMA_PATH) e utilizado na camada Silver.

### üìà Impacto de Neg√≥cio

O modelo final permite responder a perguntas cr√≠ticas como hor√°rios de pico de pousos/decolagens,  propor√ß√£o de aeronaves estrangeiras vs. nacionais e identifica√ß√£o de comportamentos de voo (taxiando, cruzeiro ou aproxima√ß√£o), transformando coordenadas GPS em intelig√™ncia operacional.

## Arquitetura do Projeto (Sistema)
O ecossistema foi constru√≠do sobre Docker, utilizando o Docker Compose para orquestrar m√∫ltiplos containers. O Apache Airflow atua como o orquestrador central, gerenciando o ciclo de vida dos dados desde a captura via Python Producer at√© a modelagem final no dbt. A persist√™ncia dos dados brutos √© feita em HDFS (Apache Spark), garantindo uma estrutura de Data Lakehouse resiliente.

```T
[ CAMADA DE INFRA ] -> Docker & Docker Compose (Isolamento)
[ CAMADA DE CONTROLE ] -> Apache Airflow (DAG Orchestration)
[ CAMADA DE INGEST√ÉO ] -> Python (Producer/Consumer) + Kafka (Stream)
[ CAMADA DE STORAGE ] -> HDFS (Parquet) + SQL Server (Bronze)
[ CAMADA DE ANALYTICS ] -> dbt (Silver/Gold)
[ CAMADA DE CONSUMO ] -> Power BI (Semantic Layer)
```
## Arquitetura Medallion
O projeto adota a Arquitetura Medallion, organizando o fluxo de dados em camadas de maturidade:

  * Bronze: Persist√™ncia dos dados brutos em HDFS (via Spark) e tabelas auxiliares em SQL Server.
  * Silver: Processos de limpeza, casting e padroniza√ß√£o via dbt Staging.
  * Gold: Modelagem dimensional (Star Schema) otimizada para consumo em ferramentas de BI.

## Modelagem de Dados

### ü•á Camada Gold: O Data Warehouse (DW)
Nesta etapa, os dados transformados s√£o organizados em um ambiente anal√≠tico. O diagrama abaixo representa o fluxo final dentro do DW.

```T
[ RAW_DATABASE ]
   +------------------+
   | flights_raw      |
   | (Dado Bruto)     |
   +------------------+
            |
            |  dbt run (Staging)
            v
    [ ZONA_SILVER ]
   +------------------+
   | stg_flights      | 
   | (View/Limpeza)   | --- Limpeza b√°sica, sele√ß√£o e
   +------------------+     casting de tipos (Float/Int).
            |
            |  dbt run (Marts) + dbt test
            v
    [ ZONA_GOLD ]
   +------------------+         +-----------------------+
   | dim_aircrafts    | <-------|                       |
   | dim_airports     | <-------|      fct_flights      |
   | dim_calendar     | <-------|  (Star Schema Final)  |
   +------------------+         +-----------------------+
          
    Valida√ß√£o: 7 testes PASS (Unique, Not Null, Accepted Values)
```

### ‚≠ê Modelo Dimensional (Star Schema)
Para otimizar a performance das consultas no Power BI, estruturamos os dados seguindo o modelo Star Schema:

```t
DIM_AIRCRAFTS                    DIM_AIRPORTS
      +----------------+               +----------------+
      | aircraft_id    | <---+         | airport_code   | <---+
      | (PK)           |     |         | (PK)           |     |
      | model          |     |         | airport_name   |     |
      | manufacturer   |     |         | city           |     |
      +----------------+     |         +----------------+     |
                             |                                |
                             |       FCT_FLIGHTS              |
                             |      +----------------+        |
                             +----- | flight_pk (PK) |        |
                                    | aircraft_id(FK)|        |
               DIM_CALENDAR  +----- | airport_code(FK) -------+
              +-------------+       | flight_date(FK)|
              | flight_date | <---+ | speed_kmh      |
              | (PK)        |       | flight_status..|
              | day / month |       +----------------+
              | year        |
              +-------------+

      Modelagem Dimensional (Star Schema)
```

### Principais Componentes
### üìê Dimens√µes

 * DIM_AIRCRAFTS - Hierarquia geogr√°fica
 * DIM_AIRPORTS - Segmenta√ß√£o e localiza√ß√£o
 * DIM_CALENDAR - Hierarquia temporal completa

### üìä Tabelas Fato 

 * FCT_FLIGHTS - opera√ß√µes de voos


## üíº Processos de Neg√≥cio

O processo de neg√≥cio no DW √© modelado atrav√©s de uma tabela fato. 

**Processo: FLIGHTS**

```Text
FCT_FLIGHTS
‚îú‚îÄ Granularidade: 1 snapshot de telemetria por aeronave a cada registro captado.
‚îú‚îÄ Frequ√™ncia: Cont√≠nua (atualizada via stream Kafka/Spark em tempo real).
‚îú‚îÄ Tipo: Transactional Fact Table (telemetria geoespacial).
‚îú‚îÄ Volume: Cresce conforme o tr√°fego a√©reo nos pol√≠gonos de monitoramento de SP.
‚îî‚îÄ Perguntas respondidas:
   ‚Ä¢ Quantos avi√µes √∫nicos sobrevoam S√£o Paulo por hora/per√≠odo?
   ‚Ä¢ Qual o volume de tr√°fego a√©reo por aeroporto (GRU vs CGH)?
   ‚Ä¢ Qual a velocidade m√©dia dos voos em procedimento de aproxima√ß√£o?
   ‚Ä¢ Aeronaves estrangeiras t√™m perfil de altitude diferente das nacionais?
   ‚Ä¢ Qual o hor√°rio de pico de pousos e decolagens durante a semana?
   ‚Ä¢ Qual a propor√ß√£o de aeronaves em solo vs. em voo por faixa hor√°ria?
   ‚Ä¢ Como a altitude m√©dia varia para voos que cruzam a regi√£o de SP?
```

## üìä Hierarquias
**1. Hierarquia Temporal (DIM_CALENDAR)**

Esta estrutura permite que o usu√°rio saia de uma vis√£o anual e chegue at√© o detalhe da hora exata do voo.

```T 
Hierarquia Temporal
Ano (2026)
 ‚îî‚îÄ‚îÄ Trimestre (Q1, Q2, Q3, Q4)
      ‚îî‚îÄ‚îÄ M√™s (Janeiro, Fevereiro, ...)
           ‚îî‚îÄ‚îÄ Dia (1, 2, 3, ..., 31)
                ‚îî‚îÄ‚îÄ Per√≠odo do Dia (Manh√£, Tarde, Noite)
                     ‚îî‚îÄ‚îÄ Hora (0, 1, 2, ..., 23)
```
**2. Hierarquia Geogr√°fica (DIM_AIRPORTS)**

Essencial para o seu estudo sobre os aeroportos de S√£o Paulo, 
permitindo agrupar por regi√£o ou aeroporto espec√≠fico.

```T
Hierarquia Geogr√°fica
Regi√£o (Sudeste)
 ‚îî‚îÄ‚îÄ Estado (S√£o Paulo)
      ‚îî‚îÄ‚îÄ Cidade (S√£o Paulo)
           ‚îî‚îÄ‚îÄ Aeroporto (Guarulhos, Congonhas, Viracopos)
                ‚îî‚îÄ‚îÄ C√≥digo IATA (GRU, CGH, VCP)
```
**3. Hierarquia de Aeronaves (DIM_AIRCRAFTS)**

Organiza a frota para responder sobre a origem do tr√°fego a√©reo.

```T
Hierarquia de Aeronaves
Categoria (Nacional / Estrangeiro)
 ‚îî‚îÄ‚îÄ Continente (Am√©rica do Sul, Europa, ...)
      ‚îî‚îÄ‚îÄ Pa√≠s de Origem (Brazil, United States, ...)
           ‚îî‚îÄ‚îÄ ID da Aeronave (ICAO24)
```

**4. Hierarquia de Navega√ß√£o Anal√≠tica (FCT_FLIGHTS)**

Organiza os dados para identificar em qual fase do voo o sinal foi capturado, permitindo an√°lises de seguran√ßa e efici√™ncia em aproxima√ß√µes.

```T
Hierarquia de Navega√ß√£o
Status do Voo (Em Voo / No Solo)
 ‚îî‚îÄ‚îÄ Comportamento (Cruzeiro, Subida, Descida / Aproxima√ß√£o, Nivelado, T√°xi)
      ‚îú‚îÄ‚îÄ Faixa de Altitude (Baixa, M√©dia, Alta Altitude)
      ‚îî‚îÄ‚îÄ Faixa de Velocidade (Lento, Cruzeiro M√©dio, Alta Velocidade)
```

 * flight_status: Separa√ß√£o macro entre aeronaves operando em pista ou em espa√ßo a√©reo.
 * flight_behavior: Identifica a fase do voo utilizando a l√≥gica de vertical_rate (taxa de subida/descida).
 * altitude_tier e speed_tier: Categoriza√ß√£o t√©cnica que transforma dados cont√≠nuos (n√∫meros) em dados categ√≥ricos (grupos), facilitando a cria√ß√£o de filtros e dashboards executivos.

**M√©tricas Principais:**

Utiliza C√°lculos DAX otimizados no POWER BI (Camada sem√¢ntica).

Para garantir a precis√£o dos dados, o projeto n√£o utiliza contagens simples de registros, mas sim medidas calculadas que tratam a natureza dos dados de avia√ß√£o:

 * Total de Sinais: COUNT(flight_pk)
 * Aeronaves Ativas: DISTINCTCOUNT(aircraft_id)
 * Velocidade M√©dia: AVG(speed_kmh)
 * Pico de Tr√°fego: MAX(unique_aircrafts) por hour_24

## üîÑ Fluxo de Dados
**1. Sistema Fonte (API EXTERNA)**

 * OpenSKy: Coleta de dados via REST API para capturar o estado global (states) das aeronaves na Bounding Box de S√£o Paulo.

**2. Extra√ß√£o (ETL - Extract)**

 Ingest√£o e Mensageria (Real-time Layer):

 * Python Producer (task_producer): Atua como o Ingestor. Ele faz a requisi√ß√£o √† API OpenSky e publica as mensagens brutas no t√≥pico do Kafka.

 * Kafka Consumer (task_consume): Ele faz parte da extra√ß√£o porque √© quem "retira" o dado da fila (mensageria) e o traz para o sistema de arquivos local (JSON) para ser processado.

 Orquestra√ß√£o e Otimiza√ß√£o de Recursos:

 * Task branch_consumer: BranchOperator para verificar se houve captura de dados antes de subir o cluster Spark, economizando recursos computacionais.

**3. Transforma√ß√£o (ETL - Transform)**

 * A. Processamento Distribu√≠do (Spark)

    * Processamento Spark (task_parquet): Realiza a primeira transforma√ß√£o estrutural, convertendo os arquivos semi-estruturados (JSON) em Apache Parquet. Isso otimiza o armazenamento no HDFS e prepara os dados para leitura em alta performance.
    
 * B. Modelagem Anal√≠tica (dbt)

    Aqui acontece a transforma√ß√£o de neg√≥cio (Silver e Gold):

    * dbt run (task_dbt_run): Executa a l√≥gica SQL (Geofencing, Tiers de Altitude, Status de Voo).

    * dbt test (task_dbt_test): Garante a qualidade (Data Quality) antes do dado chegar ao Power BI.

**4. Carga (ETL - Load)**

A carga √© realizada em dois momentos cruciais para garantir a disponibilidade do dado:

 * Ingest√£o no Data Warehouse (task_parquet_to_sql): O Spark atua como o conector, movendo os dados processados do HDFS diretamente para a tabela Bronze (FLIGHT_RAW) do SQL Server via JDBC.

 * Garantia de Qualidade (task_dbt_test): Antes de considerar a carga finalizada, s√£o executados testes de integridade (Unique, Not Null, Accepted Values). Se um teste falha, o pipeline √© interrompido, impedindo que dados corrompidos cheguem ao Dashboard.

 * Arquivamento (task_archive): O arquivo original √© movido para uma zona de "Processados", mantendo o Staging limpo e garantindo a idempot√™ncia do pipeline (o dado n√£o ser√° processado duas vezes).

**5. An√°lise e Consumo**

O pipeline processa dados brutos da API OpenSky utilizando scripts Python e Spark para realizar o geofencing (delimita√ß√£o geogr√°fica) e a limpeza dos dados. O objetivo central √© o monitoramento da malha a√©rea de alta densidade da Grande S√£o Paulo, transformando registros de telemetria bruta em indicadores de performance aeroportu√°ria.

Os dados s√£o recebidos via API em formato JSON estruturado como um vetor de vetores (Array of Arrays). Cada sub-vetor representa um State Vector individual, que √© ent√£o mapeado para colunas nomeadas e tipadas durante a fase de processamento Spark, garantindo a integridade do esquema (Schema Enforcement).

O volume significativo de dados classificados como Espa√ßo A√©reo Geral (N/A) reflete a alta densidade do tr√°fego de sobrevoo na regi√£o metropolitana de S√£o Paulo. O modelo foi desenhado para filtrar e identificar com precis√£o apenas as aeronaves em Opera√ß√£o Terminal (pouso, decolagem e t√°xi) nos tr√™s principais hubs (GRU, CGH e VCP), descartando os voos em rota de cruzeiro que n√£o interagem com os aeroportos monitorados.

A an√°lise das velocidades m√©dias no Aeroporto de Congonhas (SBSP) revelou valores significativamente baixos (aprox. 18 m/s). Embora o campo category da API OpenSky n√£o estivesse dispon√≠vel no dataset para segmenta√ß√£o direta, a baixa velocidade, somada ao perfil operacional de SBSP (maior hub de helic√≥pteros e avia√ß√£o executiva do Brasil), sugere uma forte presen√ßa de aeronaves de pequeno porte e tr√°fego de solo na amostra coletada.

**-> Diagrama Completo do Fluxo:**

```T
Airflow (Orquestrador Docker)
                         |
                         v
    +---------------------------------------------------+
    |  OpenSky API ‚îÄ‚îÄ> Producer (Python) ‚îÄ‚îÄ> Kafka      |
    |                                         |         |
    |  JSON (Local) <‚îÄ‚îÄ Consumer (Python) <‚îÄ‚îÄ‚îÄ‚îò         |
    |      |                                            |
    |      ‚îî‚îÄ‚îÄ> Spark (Batch Processing)                |
    |             ‚îî‚îÄ‚îÄ> HDFS (Armazenamento Parquet)     |
    |                    ‚îî‚îÄ‚îÄ> SQL Server (Bronze)       |
    |                                |                  |
    |                          dbt (Analytics)          |
    +---------------------------------------------------+
                         |
                         v
                [ Camada de Visualiza√ß√£o ]
                (Power BI - Star Schema)
```
**-> Diagrama detalhado:**

```T
[ DIRET√ìRIO DE SCHEMAS ]
               |
      flight_schema.py (Defini√ß√£o StructType)
               |
               v
+-----------------------------------------------------------------------+
|                       ORQUESTRADOR AIRFLOW (DAG)                      |
|                                                                       |
|  1. [PRODUCER] ----> 2. [CONSUMER]                                    |
|     (Kafka)             (Kafka)                                       |
|                            |                                          |
|                            v                                          |
|                +-----------------------+                              |
|                |   DIRET√ìRIO STAGING   |                              |
|                | flights_{{ts}}.json   |                              |
|                +-----------+-----------+                              |
|                            |                                          |
|             (Branch: Se count > 0 segue...)                           |
|                            |                                          |
|                            v                                          |
|                3. [TASK SAVE PARQUET] <--- (Usa flight_schema.py)     |
|                            |                                          |
|                +-----------v-----------+                              |
|                |      HDFS STORAGE     |                              |
|                | data/flights/parquet  |                              |
|                +-----------+-----------+                              |
|                            |                                          |
|                4. [TASK PARQUET TO SQL]                               |
|                            |                                          |
|                +-----------v-----------+                              |
|                |   SQL SERVER BRONZE   |                              |
|                +-----------+-----------+                              |
|                            |                                          |
|                5. [TASK ARCHIVE JSON]                                 |
|               (Move e Limpa o Staging)                                |
|                            |                                          |
|                +-----------v-----------+                              |
|                |  DIRET√ìRIO PROCESSED  |                              |
|                | (Hist√≥rico de JSONs)  |                              |
|                +-----------+-----------+                              |
|                            |                                          |
|                6. [DBT RUN / TEST]                                    |
|               (Bronze -> Silver -> Gold)                              |
|                                                                       |
+-----------------------------------------------------------------------+
```

**-> Manuten√ß√£o do Pipeline:**

    √Årea de Staging(diret√≥rio): Implementada para isolar os dados brutos antes da convers√£o para Parquet.

    Cleanup: O pipeline foi configurado para limpar a staging ap√≥s o processamento bem-sucedido. Arquivos remanescentes nesta pasta indicam interrup√ß√µes no ciclo de processamento, facilitando o rastreio de falhas (reprocessamento).


-> Diagrama de Fluxo do DBT: 

```T
[ CAMADA BRONZE ]            [ CAMADA SILVER ]                [ CAMADA GOLD ]
   (SQL Server)               (SQL Server)                    (Modelagem Star-SQL Server)
      |                            |                                |
+--------------+             +--------------+                +-----------------+
| RAW.         |             | STG_         |                | DIM_AIRCRAFTS   |
| FLIGHTS_RAW  |             | FLIGHTS      |                | (Tabela)        |
|--------------|    dbt run  |--------------|                |-----------------|
| id_surrogate |------------>| flight_pk    |-----+--------> | aircraft_id (PK)|
| icao24       |  (Limpeza e | aircraft_id  |     |          | origin_country  |
| callsign     |    Casting) | airport_code |     |          | category        |
| velocity     |             | speed_kmh    |     |          | continent...    |
| ...          |             | flight_date  |     |          +-----------------+
+--------------+             +--------------+     |                  ^
                                    |             |                  |
                                    |             |          +-----------------+
                             [ dbt test ]         |          |   FCT_FLIGHTS   |
                             (Data Quality)       |          |    (Tabela)     |
                                    |             |          |-----------------|
                                    |             +--------> | flight_pk (PK)  |
                                 dbt run          |--------> | aircraft_id (FK)|
                               (Geofencing)       |--------> | airport_code(FK)|
                                    |             |--------> | flight_date (FK)|
                                    v             |          | latitude        |
                             +--------------+     |          | longitude       |
                             |  TABELAS GOLD|-----+          | altitude_baro   |
                             +--------------+                | vertical_rate   |
                                    |                        | on_ground       |
                                    |                        | flight_status   |
                                    v                        +-----------------+
                             +--------------+                        |
                             | DIM_AIRPORTS | <----------------------+
                             | DIM_CALENDAR | <----------------------+
                             +--------------+

      [ PROCESSO DBT ]             [ QUALIDADE ]             [ VISUALIZA√á√ÉO ]
      - Sources (Raw)           - Unique / Not Null          - Power BI
      - Models (SQL)            - Accepted Values            - Dashboards
      - Materialization         - Relationships              - Analytics
```

**6. Visualiza√ß√£o do Airflow e Containers no Docker**

![Airflow](./screenshots/airflow.jpg)

![Containers-Docker](./screenshots/docker.jpg)

## üìö Conclus√£o e Pr√≥ximos Passos
Este projeto demonstra a implementa√ß√£o de uma arquitetura de dados moderna (Modern Data Stack), partindo da ingest√£o de eventos em tempo real at√© a entrega de insights estrat√©gicos. 

A separa√ß√£o clara entre a **Camada de Dados (SQL/dbt)** e a **Camada Sem√¢ntica (Power BI)** permite que o sistema seja escal√°vel, permitindo a adi√ß√£o de novos aeroportos e m√©tricas sem a necessidade de reestruturar todo o pipeline. A utiliza√ß√£o de modelagem Dimensional (Star Schema) garante que an√°lises complexas, como o cruzamento de performance t√©cnica com a origem da frota, sejam realizadas com alta performance.

Atualmente, a dimens√£o de aeronaves (DIM_AIRCRAFTS) foca na identifica√ß√£o √∫nica via ICAO24 e Pa√≠s de Origem. Um roadmap futuro para este projeto inclui o cruzamento com bases externas (como a da ANAC ou OpenSky DB) para enriquecimento de dados com Modelo, Fabricante e Capacidade de Passageiros.

>**NOTA:**
>Para ver as evid√™ncias do pipeline em execu√ß√£o e os Dashboards finais, 
>acesse: Detalhamento Visual e Artefatos  ![Visualiza√ß√£o de Dados](./visualizacao_dados.md)
